{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNet, tv_model\n",
    "from learning import Learn, Selector, Metrics\n",
    "import dataset\n",
    "from dataset import SKDS, TVDS, CDataset\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Dummy(CDataset):\n",
    "    \n",
    "    def load_data(self, boom='bust'):\n",
    "        data = {1: (np.asarray([1,2,3,4]), np.asarray(100), ['apple','dog']),\n",
    "                2: (np.asarray([5,6,7,8]), np.asarray(200), ['orange','cat'])}\n",
    "        print(boom)\n",
    "        return data\n",
    "    \n",
    "ds_params = {'train_params': {'embed': [('fruit',2,8,False,False),\n",
    "                                        ('pet',2,8,False,False)],\n",
    "                              'embed_lookup': {'fruit': {'apple': 1,\n",
    "                                                         'orange': 2},\n",
    "                                               'pet': {'dog': 1,\n",
    "                                                       'cat': 2}},\n",
    "             'boom': 'bang'}}\n",
    "    \n",
    "d = Dummy(**ds_params['train_params'])\n",
    "d[1]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'D_in': 256, \n",
    "                'H': 512, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'embed': [],\n",
    "                              'make': 'make_regression',\n",
    "                              'transform': None,\n",
    "                              'target_transform': None,\n",
    "                              'sk_params': {'n_samples': 10000,\n",
    "                                            'n_features': 256,\n",
    "                                            'n_informative': 200}}}\n",
    "             \n",
    "metrics_params = {'report_interval': 10}                         \n",
    "             \n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=MSELoss,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False,\n",
    "          batch_size=256, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKDS created...\n",
      "CModel loaded...\n",
      "FFNet model loaded...\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-228b5bf52581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0mmetrics_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0madapt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_embed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m           batch_size=256, epochs=100)\n\u001b[0m",
      "\u001b[0;32m~/cosmosis/learning.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, Datasets, Model, Sampler, Metrics, Optimizer, Scheduler, Criterion, ds_params, model_params, sample_params, opt_params, sched_params, crit_params, metrics_params, adapt, load_model, load_embed, save_model, batch_size, epochs)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cosmosis/learning.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msk_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cosmosis/learning.py\u001b[0m in \u001b[0;36msk_metric\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             self.sk_log.append(self.skm(\n\u001b[0;32m---> 55\u001b[0;31m                 self.sk_data[0][:,0], self.sk_data[0][:,1], **self.sk_params))\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msk_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmosis/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmosis/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[0;32m--> 386\u001b[0;31m                                          multi_class, average, sample_weight)\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmosis/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \"\"\"\n\u001b[1;32m    442\u001b[0m     \u001b[0;31m# validation of the input y_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         raise ValueError(\n\u001b[1;32m    445\u001b[0m             \u001b[0;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmosis/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "model_params = {'D_in': 256, \n",
    "                'H': 512, \n",
    "                'D_out': 4, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'embed': [],\n",
    "                              'make': 'make_classification',\n",
    "                              'transform': transforms.Compose([dataset.AsTensor()]),\n",
    "                              'target_transform': transforms.Compose(\n",
    "                                                      [dataset.DType('int64'),\n",
    "                                                       dataset.AsTensor(),\n",
    "                                                       dataset.Squeeze()]),\n",
    "                              'sk_params': {'n_samples': 10000,\n",
    "                                            'n_features': 256,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovo'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 5,\n",
    "                'cooldown': 5}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss,\n",
    "          model_params=model_params, ds_params=ds_params, \n",
    "          sample_params=sample_params, opt_params=opt_params, \n",
    "          sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False,\n",
    "          batch_size=256, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'model_name': 'resnet18',\n",
    "                'in_channels': 1,\n",
    "                'tv_params': {'num_classes': 10}}\n",
    "\n",
    "ds_params={'train_params': {'embed': [],\n",
    "                            'dataset': 'MNIST',\n",
    "                            'tv_params': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'download': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                           transforms.Resize(224),\n",
    "                                                           transforms.ToTensor()]),\n",
    "                                          'target_transform': None}},\n",
    "           'test_params': {'embed': [],\n",
    "                           'dataset': 'MNIST',\n",
    "                           'tv_params': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'download': True,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                         transforms.Resize(224),\n",
    "                                                         transforms.ToTensor()]),\n",
    "                                         'target_transform': None}}}\n",
    "        \n",
    "opt_params = {'lr': 0.01}\n",
    "crit_params = {'reduction': 'sum'}\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.8,)}\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 1,\n",
    "                'cooldown': 1}\n",
    "\n",
    "l = Learn([TVDS,TVDS], tv_model, Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=CrossEntropyLoss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          adapt=False, load_model=False, load_embed=False, save_model=False,\n",
    "          batch_size=64, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_params = {'embed': [],\n",
    "              'make': 'make_classification',\n",
    "              'transform': None,\n",
    "              'target_transform': None,\n",
    "              'sk_params': {'n_samples': 10000,\n",
    "                            'n_features': 128,\n",
    "                            'n_informative': 100,\n",
    "                            'n_classes': 4}}\n",
    "\n",
    "skds = SKDS(**ds_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
