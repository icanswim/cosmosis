{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples using the icanswim/cosmosis data science and machine learning repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNet, tv_model\n",
    "from learning import Learn, Selector, Metrics\n",
    "from dataset import SKDS, TVDS, CDataset, ImageDatasetStats, AsTensor, Squeeze, DType\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of generic/custom dataset and transforms\n",
    "import numpy as np\n",
    "\n",
    "class DummyDataset(CDataset):\n",
    "\n",
    "    def load_data(self, boom='bust'):\n",
    "        \n",
    "        datadic = {1: {'feature_1': np.asarray([.04]),\n",
    "                       'feature_2': np.asarray([.02]),\n",
    "                       'feature_3': np.asarray(['c']),\n",
    "                       'feature_4': np.asarray(['b','a']),\n",
    "                       'feature_5': np.asarray([1.1])},\n",
    "                   2: {'feature_1': np.asarray([.03]),\n",
    "                       'feature_2': np.asarray([.01]),\n",
    "                       'feature_3': np.asarray(['a','b','d']),\n",
    "                       'feature_4': np.asarray(['d']),\n",
    "                       'feature_5': np.asarray([1.2])}}\n",
    "        \n",
    "        print(boom)\n",
    "        return datadic\n",
    "    \n",
    "class DummyTransform():\n",
    "    def __call__(self, arr):\n",
    "        return np.add(arr, 2)\n",
    "    \n",
    "class DummyTransformTwo():\n",
    "    def __call__(self, arr):\n",
    "        return np.multiply(arr, .1)\n",
    "    \n",
    "ds_params = {'train_params': {'features': ['feature_1','feature_5'],\n",
    "                              'embeds': ['feature_3','feature_4'],\n",
    "                              'targets': ['feature_2'],\n",
    "                              'embed_lookup': {'a': 1, 'b': 2, 'c': 3, 'd': 4, '0': 0},\n",
    "                              'transform': [DummyTransform(), DummyTransformTwo()],\n",
    "                              'target_transform': [],\n",
    "                              'pad': 5,\n",
    "                              'do_not_pad': ['feature_1','feature_2','feature_3'],\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "d = DummyDataset(**ds_params['train_params'])\n",
    "d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of sklearn regression dataset wrapper\n",
    "ds_params = {'train_params': {'features': ['X'],\n",
    "                              'targets': ['y'],\n",
    "                              'make': 'make_regression',\n",
    "                              'sk_params': {'n_samples': 100,\n",
    "                                            'n_features': 5},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'float32'}}\n",
    "\n",
    "sk = SKDS(**ds_params['train_params'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of sklearn classification dataset wrapper\n",
    "ds_params = {'train_params': {'features': ['X'],\n",
    "                              'targets': ['y'],\n",
    "                              'make': 'make_classification',\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'sk_params': {'n_samples': 100,\n",
    "                                            'n_features': 10,\n",
    "                                            'n_informative': 8,\n",
    "                                            'n_clusters_per_class': 2,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.01,\n",
    "                                            'n_classes': 4}}}\n",
    "\n",
    "sk = SKDS(**ds_params['train_params'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of torchvision wrapper\n",
    "ds_params={'dataset': 'MNIST',\n",
    "           'features': ['images'],\n",
    "           'targets': ['labels'],\n",
    "           'tv_params': {'root': './data/',\n",
    "                         'train': True,\n",
    "                         'download': True,\n",
    "                         'transform': transforms.Compose([\n",
    "                                           transforms.Resize(224)]),\n",
    "                         'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_params)\n",
    "tvds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of torchvision dataset wrapper with PIL transform\n",
    "ds_params={'dataset': 'MNIST',\n",
    "           'tv_params': {'root': './data/',\n",
    "                         'train': True,\n",
    "                         'download': True,\n",
    "                         'transform': transforms.Compose([\n",
    "                                           transforms.Resize(224)]),\n",
    "                         'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_params)\n",
    "ids = ImageDatasetStats(tvds)\n",
    "\n",
    "print('mean: ', ids.stats.mean)\n",
    "print('stddev: ', ids.stats.stddev)\n",
    "\n",
    "#mean: 33.3/255 = .13\n",
    "#stddev: 73.7/255 = .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example sklearn regression dataset wrapper with custom model\n",
    "model_params = {'D_in': 256, \n",
    "                'H': 512, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'features': ['X'],\n",
    "                              'targets': ['y'],\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'float32',\n",
    "                              'make': 'make_regression',\n",
    "                              'as_tensor': True,\n",
    "                              'transform': [],\n",
    "                              'sk_params': {'n_samples':20000,\n",
    "                                            'n_features': 256,\n",
    "                                            'n_informative': 200}}}\n",
    "             \n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}                         \n",
    "             \n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=MSELoss,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params, \n",
    "          batch_size=256, epochs=10, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDataset created...\n",
      "SKDS make_classification created...\n",
      "FFNet model loaded...\n",
      "CModel loaded...\n",
      "running model on gpu...\n",
      "learning time: 0:00:04.885960\n",
      "epoch: 0, lr: 0.01\n",
      "train loss: 1.336085633043841, val loss: 1.2429821949738722\n",
      "sklearn train metric: 0.5990231756308837, sklearn validation metric: 0.6825792688986136\n",
      "learning time: 0:00:19.112324\n",
      "epoch: 3, lr: 0.01\n",
      "train loss: 0.9586551920834915, val loss: 0.9121038220886492\n",
      "sklearn train metric: 0.8317692414518079, sklearn validation metric: 0.8503992773542438\n",
      "learning time: 0:00:33.308543\n",
      "epoch: 6, lr: 0.01\n",
      "train loss: 0.6007211318055352, val loss: 0.6137938507092304\n",
      "sklearn train metric: 0.9354229664583389, sklearn validation metric: 0.9333483685894141\n",
      "learning time: 0:00:47.450292\n",
      "epoch: 9, lr: 0.01\n",
      "train loss: 0.45096382067535384, val loss: 0.5060073409834479\n",
      "sklearn train metric: 0.9593042295694121, sklearn validation metric: 0.9512783667866729\n",
      "test loss: 0.5127375890047122\n",
      "learning time: 0:00:48.112653\n",
      "sklearn test metric: \n",
      "0.9498766272351349 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Example sklearn classification dataset and metrics wrapper with custom model\n",
    "model_params = {'D_in': 256, \n",
    "                'H': 128, \n",
    "                'D_out': 4, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'features': 'X',\n",
    "                              'targets': 'y',\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'make': 'make_classification',\n",
    "                              'sk_params': {'n_samples': 100000,\n",
    "                                            'n_features': 300,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_clusters_per_class': 3,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.1,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 5,\n",
    "                'cooldown': 5}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss,\n",
    "          model_params=model_params, ds_params=ds_params, \n",
    "          sample_params=sample_params, opt_params=opt_params, \n",
    "          sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          adapt=(300,256,.2), batch_size=128, epochs=10, squeeze_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "CDataset created...\n",
      "TVDS created...\n",
      "Files already downloaded and verified\n",
      "CDataset created...\n",
      "TVDS created...\n",
      "TorchVision model resnet18 loaded...\n",
      "running model on gpu...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d(): argument 'input' (position 1) must be Tensor, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f3afb7bf823a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 'cooldown': 1}\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m l = Learn([TVDS,TVDS], \n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0mtv_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mSelector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cosmosis/learning.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, Datasets, Model, Sampler, Metrics, Optimizer, Scheduler, Criterion, ds_params, model_params, sample_params, opt_params, sched_params, crit_params, metrics_params, adapt, load_model, load_embed, save_model, batch_size, epochs, squeeze_y, gpu)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle_train_val_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cosmosis/learning.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.8/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d(): argument 'input' (position 1) must be Tensor, not dict"
     ]
    }
   ],
   "source": [
    "## Example torchvision dataset, transforms and model wrapper\n",
    "model_params = {'model_name': 'resnet18',\n",
    "                'in_channels': 3,\n",
    "                'tv_params': {'num_classes': 10}}\n",
    "\n",
    "ds_params={'train_params': {'dataset': 'CIFAR10',\n",
    "                            'tv_params': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'download': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                           transforms.RandomRotation(10),\n",
    "                                                           transforms.Resize(64),\n",
    "                                                           transforms.ToTensor()]),\n",
    "                                          'target_transform': None,\n",
    "                                          'download': True}},\n",
    "           'test_params': {'dataset': 'CIFAR10',\n",
    "                           'tv_params': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'download': True,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                         transforms.Resize(64),\n",
    "                                                         transforms.ToTensor()]),\n",
    "                                         'target_transform': None,\n",
    "                                         'download': True}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 1,\n",
    "                'cooldown': 1}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=CrossEntropyLoss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params, \n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params, \n",
    "          batch_size=16, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example torchvision dataset and model wrapper\n",
    "model_params = {'model_name': 'resnext50_32x4d',\n",
    "                'in_channels': 3,\n",
    "                'tv_params': {'num_classes': 10}}\n",
    "\n",
    "ds_params={'train_params': {'dataset': 'CIFAR10',\n",
    "                            'tv_params': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                       transforms.RandomRotation(10),\n",
    "                                                       transforms.Resize(256),\n",
    "                                                       transforms.ToTensor()]),\n",
    "                                          'target_transform': None}},\n",
    "           'test_params': {'dataset': 'CIFAR10',\n",
    "                           'tv_params': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                      transforms.Resize(256),\n",
    "                                                      transforms.ToTensor()]),\n",
    "                                         'target_transform': None}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss, \n",
    "          model_params=model_params, ds_params=ds_params, \n",
    "          sample_params=sample_params, opt_params=opt_params, \n",
    "          sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=16, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
