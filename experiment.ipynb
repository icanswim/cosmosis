{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples demonstrating the use of the icanswim/cosmosis repo \n",
    "## for data science and machine learning projects.\n",
    "## This repo is intended to be used as the boiler plate for data science and machine learning projects.\n",
    "## See the icanswim/qchem repo for a demonstration of the use of this (icanswim/cosmosis) repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNet, tv_model, IdentityModel, GPT\n",
    "from learning import Learn, Selector, Metrics\n",
    "from dataset import CDataset, SKDS, TVDS, ExampleDataset\n",
    "from dataset import ImageDatasetStats, AsTensor, SqueezeN, DType, Pad1d, EmbedLookup, Reshape\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X': tensor([10.0400, 10.0000, 10.0000, 10.0000, 10.0000], dtype=torch.float64), 'X1': tensor([0.0200, 0.0300, 0.0000, 0.0000, 0.0000, 0.0400, 0.0500, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "       dtype=torch.float64), 'feature_3': tensor([1, 0, 0, 0, 0]), 'feature_4': tensor([3, 3, 4, 0, 0]), 'feature_5': tensor([1.1000, 0.0000, 0.0000, 0.0000, 0.0000], dtype=torch.float64)}\n",
      "CModel loaded...\n",
      "IdentityModel(\n",
      "  (layers): ModuleList(\n",
      "    (0): Identity()\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'feature_3': Embedding(4, 8, padding_idx=0), 'feature_4': Embedding(5, 8, padding_idx=0)}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(im)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_layer: \u001b[39m\u001b[38;5;124m'\u001b[39m, im\u001b[38;5;241m.\u001b[39membedding_layer)\n\u001b[0;32m---> 62\u001b[0m out \u001b[38;5;241m=\u001b[39m im(ed[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout: \u001b[39m\u001b[38;5;124m'\u001b[39m, out)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout.shape: \u001b[39m\u001b[38;5;124m'\u001b[39m, out\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/cosmosis/model.py:152\u001b[0m, in \u001b[0;36mCModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    150\u001b[0m             X\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m    151\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(embedded)\n\u001b[0;32m--> 152\u001b[0m     X \u001b[38;5;241m=\u001b[39m cat(X, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)      \n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX): \n\u001b[1;32m    154\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "source": [
    "#example cosmosis dataset (CDataset)\n",
    "import numpy as np\n",
    "\n",
    "class ExampleDataset(CDataset):\n",
    "    #zero is the lookup for the padding index \n",
    "    embed_lookup = {'feature_4': {'a': 1,'b': 2,'c': 3,'d': 4, '0': 0},\n",
    "                    'feature_3': {'z1': 1, 'y1': 2, 'x1': 3, '0': 0},\n",
    "                    'feature_6': {'e': 1, 'f': 2, 'g': 3, '0': 0}}\n",
    "    \n",
    "    def load_data(self, boom='bust'):\n",
    "        \n",
    "        datadic = {1: {'feature_1': np.asarray([.04]),\n",
    "                       'feature_2': np.asarray([[.02,.03],[.04,.05]]),\n",
    "                       'feature_3': np.asarray(['z1']),\n",
    "                       'feature_4': np.asarray(['c','c','d']),\n",
    "                       'feature_5': np.asarray([1.1]),\n",
    "                       'feature_6': np.asarray(['e','f','g'])},\n",
    "                   2: {'feature_1': np.asarray([.03]),\n",
    "                       'feature_2': np.asarray([[.1,.2],[.3,.4]]),\n",
    "                       'feature_3': np.asarray(['x1','z1','y1']),\n",
    "                       'feature_4': np.asarray(['d','a','d']),\n",
    "                       'feature_5': np.asarray([1.2]),\n",
    "                       'feature_6': np.asarray(['f','f','g'])}}\n",
    "        \n",
    "        print(boom)\n",
    "        return datadic\n",
    "    \n",
    "class ExampleTransform():\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        \n",
    "    def __call__(self, arr):\n",
    "        return np.add(arr, self.num)\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "lookup_feature_6 = ExampleDataset.embed_lookup['feature_6']\n",
    "ds_param = {'train_param': {'input_dict': {\n",
    "                                           #'X': ['feature_1'], \n",
    "                                           #'X1': ['feature_2'],\n",
    "                                           'feature_3': ['feature_3'],\n",
    "                                           'feature_4': ['feature_4'],\n",
    "                                           'feature_5': ['feature_5']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(5), EmbedLookup(lookup_feature_4), AsTensor()],\n",
    "                                           'feature_5': [AsTensor()],\n",
    "                                           'feature_6': [Pad1d(5), EmbedLookup(lookup_feature_6), AsTensor()]},\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'embed_param': {'feature_3': (4,8,0,False),\n",
    "                               'feature_4': (5,8,0,False),\n",
    "                               'flatten': False}}\n",
    "im = IdentityModel(model_param)\n",
    "print(im)\n",
    "print('embedding_layer: ', im.embedding_layer)\n",
    "\n",
    "out = im(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape) # X + embed_3 + embed_4 = 5 + (8 x 5) + (8 x 5) = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cosmosis blank parameters\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['feature_1','feature_2'],\n",
    "                                           'feature_3': ['feature_3']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()]},\n",
    "                            'boom': 'bang'}}\n",
    "\n",
    "model_param = {'some_param': 128, \n",
    "               'embed_param': {'feature_3': (voc,vec,padding_idx,trainable),\n",
    "                               'some_param': True,\n",
    "                               'flatten': True}} \n",
    "                                       \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([DS], \n",
    "          Model,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Optimizer, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=LossFunction,\n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=12, epochs=1, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X': tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'X1': tensor([3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'y': tensor([1.1000], dtype=torch.float64)}\n",
      "CModel loaded...\n",
      "GPT(\n",
      "  (layers): ModuleList(\n",
      "    (0): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
      "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'X': Embedding(4, 16, padding_idx=0), 'X1': Embedding(5, 16, padding_idx=0)}\n",
      "out:  tensor([[-1.0669, -0.6827, -0.3997,  1.9855,  1.1415, -0.3880, -0.4179, -0.5426,\n",
      "          0.9955, -1.5162,  1.2541,  0.5162,  0.0441, -0.8407,  1.0834, -1.1657],\n",
      "        [ 0.8305, -0.9760,  0.5492, -0.6619, -1.2255,  1.6422,  1.2430,  0.7280,\n",
      "          0.5003, -1.2198, -0.7158, -1.2349,  1.2690, -1.1780, -0.2595,  0.7093],\n",
      "        [ 1.2656, -0.3995, -0.6628, -0.3428, -0.3063,  0.1730,  1.4060,  1.0818,\n",
      "         -0.3589, -0.1803, -0.1868, -1.5058,  1.1559, -0.9706, -1.7657,  1.5973],\n",
      "        [ 0.4987, -1.2063,  0.3130, -1.0575, -0.9593,  2.1624,  1.0722,  0.3828,\n",
      "          0.4718, -1.1341, -0.1424, -1.0509,  1.3494, -1.1551, -0.1566,  0.6118],\n",
      "        [ 1.2552, -2.3329, -0.0105, -0.9254,  0.0378,  1.7967,  0.4646,  0.8076,\n",
      "          0.1076, -0.5821, -0.7223, -0.9719,  1.0859, -0.3889, -0.4467,  0.8254],\n",
      "        [ 0.3798,  0.0954,  0.7828, -0.7301, -1.7480,  1.3662,  1.0764,  0.8843,\n",
      "         -0.0384, -2.1646, -0.3970, -0.6934,  1.4298, -0.3928,  0.4638, -0.3143],\n",
      "        [ 0.6000, -0.9402,  0.6946, -0.7539, -1.3572,  2.1994,  1.2621,  0.6321,\n",
      "          0.9691, -0.5702, -1.0217, -1.3851,  0.3475, -0.8115,  0.1634, -0.0284],\n",
      "        [ 1.0293, -0.7967,  0.3693, -1.0235, -1.1464,  1.8327,  0.9774,  1.0369,\n",
      "          0.5525, -1.0914, -0.7225, -1.0907,  1.3276, -1.1911, -0.1471,  0.0837],\n",
      "        [ 1.0006, -0.8696,  0.3918, -0.3963, -1.3108,  2.0057,  0.9379,  0.2067,\n",
      "          0.5642, -1.1855, -0.6833, -1.0578,  1.2507, -1.0667, -0.6796,  0.8917],\n",
      "        [ 0.9307, -1.0563, -0.1439, -1.1424, -0.9168,  1.7551,  0.8434,  1.0311,\n",
      "          0.6040, -1.2128, -0.6461, -1.2782,  1.2910, -0.8527, -0.0505,  0.8447],\n",
      "        [ 1.4698, -0.2330,  0.2323, -1.1067, -1.2523,  1.6244,  1.1677,  0.7237,\n",
      "         -0.1809, -1.3504, -0.3137, -0.5902,  1.1154, -1.5103, -0.4286,  0.6329],\n",
      "        [ 0.4040, -0.3871,  0.7193, -0.9581, -0.7680,  1.5335,  0.1599,  1.0035,\n",
      "         -0.6355, -1.7515, -0.8021, -0.8291,  2.1518, -0.6923,  0.4628,  0.3889],\n",
      "        [ 0.9941, -1.0265,  0.8870, -0.7143, -0.9160,  2.2139,  0.8972,  0.8107,\n",
      "          0.4351, -1.1065, -0.5821, -1.4071, -0.0375, -0.8631, -0.4608,  0.8759],\n",
      "        [ 0.9690, -0.1826, -0.4150, -0.4908, -1.2675,  0.3114,  1.6539,  1.1378,\n",
      "          0.5324, -1.0815, -0.6997, -1.2405,  1.3357, -1.2257, -0.6413,  1.3044],\n",
      "        [ 0.8492, -0.7197,  0.3189, -0.8660, -1.1678,  1.9563,  1.0281,  0.6642,\n",
      "          0.3813, -1.3470, -0.7125, -1.1470,  1.3195, -1.0765, -0.1892,  0.7081],\n",
      "        [ 0.4663, -0.4186, -0.0272, -1.3618, -0.9646,  1.3361,  0.9150,  1.4517,\n",
      "          0.4925, -1.6640, -0.7669, -1.0908,  1.5484, -0.7118,  0.1965,  0.5993]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "out.shape:  torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "#example showing transformer inputs, outputs and parameters\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "lookup_feature_6 = ExampleDataset.embed_lookup['feature_6']\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['feature_3','feature_4'],\n",
    "                                           'X1': ['feature_4'],\n",
    "                                           'y': ['feature_5']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(16), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(16), EmbedLookup(lookup_feature_4), AsTensor()],\n",
    "                                           'feature_5': [AsTensor()],\n",
    "                                           'feature_6': [EmbedLookup(lookup_feature_6), AsTensor()]},\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'd_model': 16, # matches embedding dimension\n",
    "               'nhead': 4, \n",
    "               'num_layers': 2,\n",
    "               'dim_feedforward': 128,\n",
    "               'embed_param': {'feature_3': (4,16,0,True), # matches embedding_input key\n",
    "                               'feature_4': (5,16,0,True)}} # matches d_model dimension\n",
    "                                 \n",
    "\n",
    "gpt = GPT(model_param)\n",
    "print(gpt)\n",
    "print('embedding_layer: ', gpt.embedding_layer)\n",
    "out = gpt(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape) # (feature_length, embedding_lenth) = (12, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example GPT\n",
    "lookup_feature = Dataset.embed_lookup[]\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'model_key1': ['dataset_key2']},\n",
    "                                             'criterion_input': {'criterion__key': ['dataset_key3']},\n",
    "                                             'embedding_input': {'embedding_key1': ['dataset_key1']}},\n",
    "                              'transforms': {'dataset_key1': [Pad1d(), EmbedLookup(lookup_feature), AsTensor()],\n",
    "                                             'dataset_key2': [AsTensor()],\n",
    "                                             'dataset_key3': [AsTensor()]}}}\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "                'd_model': 16, # matches embedding dimension\n",
    "                'nhead': 4, \n",
    "                'num_layers': 2,\n",
    "                'dim_feedforward': 128,\n",
    "                'embed_param': {'X': [('embed_3',4,16,0,True,False)], # matches embedding_input key\n",
    "                                 'X1': [('embed_4',5,16,0,True,False)]}} # matches d_model dimension\n",
    "                                       \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([DS], \n",
    "          GPT,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Optimizer, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=LossFunction,\n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=12, epochs=1, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS)\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'target': ['y']}},\n",
    "                              'dataset': 'make_regression',\n",
    "                              'sk_param': {'n_samples': 100,\n",
    "                                            'n_features': 5},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'float32'}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS)\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'y': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'transforms': {'y': [],\n",
    "                                             'X': [AsTensor()]},\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_param': {'n_samples': 1000,\n",
    "                                            'n_features': 30,\n",
    "                                            'n_informative': 20,\n",
    "                                            'n_clusters_per_class': 3,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.1,\n",
    "                                            'n_classes': 4}}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "print(sk[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS)\n",
    "ds_param={'dataset': 'MNIST',\n",
    "           'input_dict': {'model_input': {'features': ['images'],},\n",
    "                          'criterion_input': {'target': ['labels']}},\n",
    "           'tv_param': {'root': './data/',\n",
    "                         'train': True,\n",
    "                         'download': True,\n",
    "                         'transform': transforms.Compose([transforms.Resize(224)]),\n",
    "                         'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_param)\n",
    "tvds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and PIL stats\n",
    "ds_param={'dataset': 'MNIST',\n",
    "           'tv_param': {'root': './data/',\n",
    "                         'train': True,\n",
    "                         'download': True,\n",
    "                         'transform': transforms.Compose([\n",
    "                                           transforms.Resize(224)]),\n",
    "                         'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_param)\n",
    "ids = ImageDatasetStats(tvds)\n",
    "\n",
    "print('mean: ', ids.stats.mean)\n",
    "print('stddev: ', ids.stats.stddev)\n",
    "\n",
    "#mean: 33.3/255 = .13\n",
    "#stddev: 73.7/255 = .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 512, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'y': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'float32',\n",
    "                              'dataset': 'make_regression',\n",
    "                              'sk_param': {'n_samples':20000,\n",
    "                                            'n_features': 256,\n",
    "                                            'n_informative': 200}}}\n",
    "             \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=MSELoss,\n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=256, epochs=40, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 4,\n",
    "                'softmax': 'softmax',\n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'y': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'transforms': {'y': [SqueezeN()],\n",
    "                                             'X': []},\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_param': {'n_samples': 100000,\n",
    "                                            'n_features': 300,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_redundant': 5,\n",
    "                                            'n_repeated': 5,\n",
    "                                            'n_clusters_per_class': 5,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.05,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_param = {'report_interval': 30,\n",
    "                  'log_plot': False,\n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_param': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss,\n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          adapt=(300,256,.2), \n",
    "          squeeze_y_pred=False, batch_size=128, epochs=20, \n",
    "          save_model='demo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example inference with cosmosis sklearn classification dataset wrapper (SKDS) and custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 4, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'y': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_param': {'n_samples': 10000,\n",
    "                                            'n_features': 300,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_clusters_per_class': 3,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.1,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "\n",
    "metrics_param = {}\n",
    "opt_param = {}\n",
    "sample_param = {}\n",
    "sched_param = {}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=None,\n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          batch_size=128, epochs=1, load_model='demo_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnet18',\n",
    "                'in_channels': 3,\n",
    "                'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'download': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                           transforms.RandomRotation(10),\n",
    "                                                           transforms.Resize(64),\n",
    "                                                           transforms.ToTensor()]),\n",
    "                                          'target_transform': None,\n",
    "                                          'download': True}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                           'tv_param': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'download': True,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                         transforms.Resize(64),\n",
    "                                                         transforms.ToTensor()]),\n",
    "                                         'target_transform': None,\n",
    "                                         'download': True}}}\n",
    "\n",
    "metrics_param = {'report_interval': 30, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_param': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 1,\n",
    "                'cooldown': 1}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=CrossEntropyLoss, \n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param, \n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnext50_32x4d',\n",
    "                'in_channels': 3,\n",
    "                'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                       transforms.RandomRotation(10),\n",
    "                                                       transforms.Resize(256),\n",
    "                                                       transforms.ToTensor()]),\n",
    "                                          'target_transform': None}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                           'tv_param': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                      transforms.Resize(256),\n",
    "                                                      transforms.ToTensor()]),\n",
    "                                         'target_transform': None}}}\n",
    "\n",
    "metrics_param = {'report_interval': 60, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_param': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss, \n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
