{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples demonstrating the use of the icanswim/cosmosis repo \n",
    "## for data science and machine learning projects.\n",
    "## This repo is intended to be used as the boiler plate for data science and machine learning projects.\n",
    "## See the icanswim/qchem repo for a demonstration of the use of this (icanswim/cosmosis) repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNet, tv_model, IdentityModel, GPT\n",
    "from learning import Learn, Selector, Metrics\n",
    "from dataset import CDataset, SKDS, TVDS, ExampleDataset\n",
    "from dataset import ImageDatasetStats, AsTensor, SqueezeN, DType, Pad1d, EmbedLookup, Reshape\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosmosis blank parameters\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['feature_1','feature_2'],\n",
    "                                           'feature_3': ['feature_3']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()]},\n",
    "                            'boom': 'bang'}}\n",
    "\n",
    "model_param = {'some_param': 128,\n",
    "               'X': None,\n",
    "               'y': 'y',\n",
    "               'embed_param': {'feature_3': (voc,vec,padding_idx,trainable),\n",
    "                               'some_param': True,\n",
    "                               'flatten': True}} \n",
    "                                       \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "learn = Learn([DS], \n",
    "              Model,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Optimizer, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=LossFunction,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=12, epochs=1, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X2': tensor([10.0400,  0.0200,  0.0300,  0.0400,  0.0500], dtype=torch.float64), 'X3': tensor([0.0200, 0.0300, 0.0400, 0.0500], dtype=torch.float64), 'embed_3': tensor([1, 0, 0, 0, 0]), 'embed_4': tensor([3, 3, 4, 0, 0]), 'target': tensor([1.1000], dtype=torch.float64)}\n",
      "CModel loaded...\n",
      "IdentityModel(\n",
      "  (layers): ModuleList(\n",
      "    (0): Identity()\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'embed_3': Embedding(4, 8, padding_idx=0), 'embed_4': Embedding(5, 8, padding_idx=0)}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 1 and 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(im)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_layer: \u001b[39m\u001b[38;5;124m'\u001b[39m, im\u001b[38;5;241m.\u001b[39membedding_layer)\n\u001b[0;32m---> 67\u001b[0m out \u001b[38;5;241m=\u001b[39m im(ed[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout: \u001b[39m\u001b[38;5;124m'\u001b[39m, out)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout.shape: \u001b[39m\u001b[38;5;124m'\u001b[39m, out\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/cosmo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cosmo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/cosmosis/model.py:176\u001b[0m, in \u001b[0;36mCModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m         X \u001b[38;5;241m=\u001b[39m embedded\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m         X \u001b[38;5;241m=\u001b[39m cat([X, embedded], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    179\u001b[0m     X \u001b[38;5;241m=\u001b[39m l(X)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 1 and 2"
     ]
    }
   ],
   "source": [
    "#example cosmosis dataset (CDataset)\n",
    "\n",
    "class ExampleTransform():\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        \n",
    "    def __call__(self, arr):\n",
    "        return np.add(arr, self.num)\n",
    "\n",
    "\n",
    "class ExampleDataset(CDataset):\n",
    "    #zero is the lookup for the padding index \n",
    "    embed_lookup = {'feature_4': {'a': 1,'b': 2,'c': 3,'d': 4, '0': 0},\n",
    "                    'feature_3': {'z1': 1, 'y1': 2, 'x1': 3, '0': 0},\n",
    "                    'feature_6': {'e': 1, 'f': 2, 'g': 3, '0': 0}}\n",
    "    \n",
    "    def load_data(self, boom='bust'):\n",
    "        \n",
    "        datadic = {1: {'feature_1': np.asarray([.04]),\n",
    "                       'feature_2': np.asarray([[.02,.03],[.04,.05]]),\n",
    "                       'feature_3': np.asarray(['z1']),\n",
    "                       'feature_4': np.asarray(['c','c','d']),\n",
    "                       'feature_5': np.asarray([1.1]),\n",
    "                       'feature_6': np.asarray(['e','f','g'])},\n",
    "                   2: {'feature_1': np.asarray([.03]),\n",
    "                       'feature_2': np.asarray([[.1,.2],[.3,.4]]),\n",
    "                       'feature_3': np.asarray(['x1','z1','y1']),\n",
    "                       'feature_4': np.asarray(['d','a','d']),\n",
    "                       'feature_5': np.asarray([1.2]),\n",
    "                       'feature_6': np.asarray(['f','f','g'])}}\n",
    "        \n",
    "        print(boom)\n",
    "        return datadic\n",
    "    \n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "lookup_feature_6 = ExampleDataset.embed_lookup['feature_6']\n",
    "ds_param = {'train_param': {'input_dict': {\n",
    "                                           'X2': ['feature_1','feature_2'], \n",
    "                                           'X3': ['feature_2'],\n",
    "                                           'embed_3': ['feature_3'],\n",
    "                                           'embed_4': ['feature_4'],\n",
    "                                           'target': ['feature_5'],\n",
    "                                            },\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(5), EmbedLookup(lookup_feature_4), AsTensor()],\n",
    "                                           'feature_5': [AsTensor()],\n",
    "                                           'feature_6': [Pad1d(5), EmbedLookup(lookup_feature_6), AsTensor()]},\n",
    "                            'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'X': ['X2', 'X3'],\n",
    "               'y': ['target'],\n",
    "               'embed_param': {'embed_3': (4,8,0,False),\n",
    "                               'embed_4': (5,8,0,False),\n",
    "                               'flatten': True}}\n",
    "\n",
    "im = IdentityModel(model_param)\n",
    "print(im)\n",
    "print('embedding_layer: ', im.embedding_layer)\n",
    "\n",
    "out = im(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape) # (1+4+4+5*8+5*8) = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X1': tensor([1, 0, 0, 0, 0, 0]), 'X2': tensor([3, 3, 4, 0, 0, 0]), 'y': tensor([1.1000], dtype=torch.float64)}\n",
      "CModel loaded...\n",
      "GPT(\n",
      "  (layers): ModuleList(\n",
      "    (0): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'X1': Embedding(4, 8, padding_idx=0), 'X2': Embedding(5, 8, padding_idx=0)}\n",
      "out:  tensor([[-1.2126, -1.4060,  0.1748,  0.6598,  0.4220,  0.9093, -0.9942,  1.4469],\n",
      "        [-0.0639, -1.1419,  0.6096,  0.8647,  0.3160,  0.2066, -1.9951,  1.2040],\n",
      "        [ 0.1882, -0.7674,  0.5968,  0.9446, -0.2577, -0.2283, -1.9549,  1.4788],\n",
      "        [-0.0579, -1.3364,  0.5356,  1.1478, -1.0268, -0.6504, -0.3464,  1.7346],\n",
      "        [ 0.3413, -0.7055,  0.7280,  0.2971,  0.3532,  0.0291, -2.2677,  1.2245],\n",
      "        [ 0.1790, -1.0365,  1.0334, -0.4362,  0.7606,  0.0322, -1.8337,  1.3013]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "out.shape:  torch.Size([6, 8])\n"
     ]
    }
   ],
   "source": [
    "#example showing transformer inputs, outputs and parameters\n",
    "\n",
    "class ExampleTransform():\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        \n",
    "    def __call__(self, arr):\n",
    "        return np.add(arr, self.num)\n",
    "\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "lookup_feature_6 = ExampleDataset.embed_lookup['feature_6']\n",
    "ds_param = {'train_param': {'input_dict': {'X1': ['feature_3'],\n",
    "                                           'X2': ['feature_4'],\n",
    "                                           'y': ['feature_5']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(6), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(6), EmbedLookup(lookup_feature_4), AsTensor()],\n",
    "                                           'feature_5': [AsTensor()],\n",
    "                                           'feature_6': [EmbedLookup(lookup_feature_6), AsTensor()]},\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'd_model': 8, # matches embedding dimension\n",
    "               'n_head': 2, \n",
    "               'num_layers': 2,\n",
    "               'd_vocab': None,\n",
    "               'embed_param': {'X1': (4,8,0,True), # embed key matches input_dict key ('X1')\n",
    "                               'X2': (5,8,0,True)}} # vector dimension matches d_model dimension\n",
    "                                 \n",
    "gpt = GPT(model_param)\n",
    "print(gpt)\n",
    "print('embedding_layer: ', gpt.embedding_layer)\n",
    "out = gpt(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape) # (feature_length, embedding_lenth) = (6, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS)\n",
    "                            \n",
    "ds_param = {'train_param': {'input_dict': {'model_input': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'dataset': 'make_regression',\n",
    "                            'sk_param': {'n_samples': 100,\n",
    "                                         'n_features': 5},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'float32'}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS)\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'int64',\n",
    "                            'transforms': {'y': [AsTensor()],\n",
    "                                           'X': [AsTensor()]},\n",
    "                            'dataset': 'make_classification',\n",
    "                            'sk_param': {'n_samples': 1000,\n",
    "                                         'n_features': 30,\n",
    "                                         'n_informative': 20,\n",
    "                                         'n_clusters_per_class': 3,\n",
    "                                         'flip_y': 0.05,\n",
    "                                         'class_sep': 0.1,\n",
    "                                         'n_classes': 4}}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "print(sk[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS)\n",
    "ds_param = {'train_param': {'input_dict': {'features': ['images'],\n",
    "                                           'y': ['labels']},\n",
    "                            'dataset': 'MNIST',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                         'train': True,\n",
    "                                         'download': True,\n",
    "                                         'transform': transforms.Compose([transforms.Resize(224)]),\n",
    "                                         'target_transform': None}}}\n",
    "\n",
    "tvds = TVDS(**ds_param['train_param'])\n",
    "tvds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and PIL stats\n",
    "ds_param={'dataset': 'MNIST',\n",
    "          'tv_param': {'root': './data/',\n",
    "                       'train': True,\n",
    "                       'download': True,\n",
    "                       'transform': transforms.Compose([transforms.Resize(224)]),\n",
    "                       'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_param)\n",
    "ids = ImageDatasetStats(tvds)\n",
    "\n",
    "print('mean: ', ids.stats.mean)\n",
    "print('stddev: ', ids.stats.stddev)\n",
    "\n",
    "#mean: 33.3/255 = .13\n",
    "#stddev: 73.7/255 = .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 512, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'float32',\n",
    "                            'dataset': 'make_regression',\n",
    "                            'sk_param': {'n_samples':20000,\n",
    "                                         'n_features': 256,\n",
    "                                         'n_informative': 200}}}\n",
    "             \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "learn = Learn([SKDS], \n",
    "              FFNet,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=MSELoss,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=256, epochs=40, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 4,\n",
    "                'softmax': 'softmax',\n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'int64',\n",
    "                            'transforms': {'y': [SqueezeN()],\n",
    "                                           'X': []},\n",
    "                            'dataset': 'make_classification',\n",
    "                            'sk_param': {'n_samples': 100000,\n",
    "                                         'n_features': 300,\n",
    "                                         'n_informative': 200,\n",
    "                                         'n_redundant': 5,\n",
    "                                         'n_repeated': 5,\n",
    "                                         'n_clusters_per_class': 5,\n",
    "                                         'flip_y': 0.05,\n",
    "                                         'class_sep': 0.05,\n",
    "                                         'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_param = {'report_interval': 30,\n",
    "                 'log_plot': True,\n",
    "                 'sk_metric_name': 'roc_auc_score',\n",
    "                 'sk_param': {'average': 'macro',\n",
    "                              'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1}\n",
    "\n",
    "learm = Learn([SKDS], \n",
    "              FFNet, \n",
    "              Sampler=Selector,\n",
    "              Metrics=Metrics,\n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=CrossEntropyLoss,\n",
    "              model_param=model_param, ds_param=ds_param, \n",
    "              sample_param=sample_param, opt_param=opt_param, \n",
    "              sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param,\n",
    "              adapt=(300,256,.2), \n",
    "              squeeze_y_pred=False, batch_size=128, epochs=20, \n",
    "              save_model='demo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example inference with cosmosis sklearn classification dataset wrapper (SKDS) and custom model (FFNet)\n",
    "\n",
    "model_param = {'in_channels': 256, \n",
    "               'hidden': 128, \n",
    "               'out_channels': 4, \n",
    "               'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'int64',\n",
    "                            'dataset': 'make_classification',\n",
    "                            'sk_param': {'n_samples': 10000,\n",
    "                                         'n_features': 300,\n",
    "                                         'n_informative': 200,\n",
    "                                         'n_clusters_per_class': 3,\n",
    "                                         'flip_y': 0.05,\n",
    "                                         'class_sep': 0.1,\n",
    "                                         'n_classes': 4}}}\n",
    "                                     \n",
    "learn = Learn([SKDS], \n",
    "              FFNet, \n",
    "              Sampler=Selector,\n",
    "              Metrics=Metrics,\n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=None,\n",
    "              model_param=model_param, ds_param=ds_param, \n",
    "              batch_size=128, epochs=1, load_model='demo_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnet18',\n",
    "               'in_channels': 3,\n",
    "               'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                          'tv_param': {'root': './data/',\n",
    "                                       'train': True,\n",
    "                                       'download': True,\n",
    "                                       'transform': transforms.Compose([\n",
    "                                                           transforms.RandomRotation(10),\n",
    "                                                           transforms.Resize(64),\n",
    "                                                           transforms.ToTensor()]),\n",
    "                                       'target_transform': None,\n",
    "                                       'download': True}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                          'tv_param': {'root': './data/',\n",
    "                                       'train': False,\n",
    "                                       'download': True,\n",
    "                                       'transform': transforms.Compose([\n",
    "                                                         transforms.Resize(64),\n",
    "                                                         transforms.ToTensor()]),\n",
    "                                       'target_transform': None,\n",
    "                                       'download': True}}}\n",
    "\n",
    "metrics_param = {'report_interval': 30, \n",
    "                 'sk_metric_name': 'roc_auc_score', \n",
    "                 'sk_param': {'average': 'macro',\n",
    "                              'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.8,),\n",
    "                'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "               'patience': 1,\n",
    "               'cooldown': 1}\n",
    "\n",
    "learn = Learn([TVDS,TVDS], \n",
    "              tv_model, \n",
    "              Selector, \n",
    "              Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=CrossEntropyLoss, \n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param, \n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnext50_32x4d',\n",
    "                'in_channels': 3,\n",
    "                'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                         'train': True,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                       transforms.RandomRotation(10),\n",
    "                                                       transforms.Resize(256),\n",
    "                                                       transforms.ToTensor()]),\n",
    "                                         'target_transform': None}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                           'tv_param': {'root': './data/',\n",
    "                                        'train': False,\n",
    "                                        'transform': transforms.Compose([\n",
    "                                                      transforms.Resize(256),\n",
    "                                                      transforms.ToTensor()]),\n",
    "                                        'target_transform': None}}}\n",
    "\n",
    "metrics_param = {'report_interval': 60, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_param': {'average': 'macro',\n",
    "                               'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.8,),\n",
    "                'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss, \n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
