{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples demonstrating the use of the icanswim/cosmosis repo \n",
    "## for data science and machine learning projects.\n",
    "## This repo is intended to be used as the boiler plate for data science and machine learning projects.\n",
    "## See the icanswim/qchem repo for a demonstration of the use of this (icanswim/cosmosis) repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNet, tv_model, IdentityModel, GPT\n",
    "from learning import Learn, Selector, Metrics\n",
    "from dataset import CDataset, SKDS, TVDS, ExampleDataset\n",
    "from dataset import ImageDatasetStats, AsTensor, SqueezeN, DType, Pad1d, EmbedLookup, Reshape\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cosmosis blank parameters\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['feature_1','feature_2'],\n",
    "                                           'feature_3': ['feature_3']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()]},\n",
    "                            'boom': 'bang'}}\n",
    "\n",
    "model_param = {'some_param': 128,\n",
    "               'X': None,\n",
    "               'y': 'y',\n",
    "               'embed_param': {'feature_3': (voc,vec,padding_idx,trainable),\n",
    "                               'some_param': True,\n",
    "                               'flatten': True}} \n",
    "                                       \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([DS], \n",
    "          Model,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Optimizer, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=LossFunction,\n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=12, epochs=1, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X2': tensor([10.0400,  0.0200,  0.0300,  0.0400,  0.0500], dtype=torch.float64), 'X3': tensor([0.0200, 0.0300, 0.0400, 0.0500], dtype=torch.float64), 'embed_3': tensor([1, 0, 0, 0, 0]), 'embed_4': tensor([3, 3, 4, 0, 0]), 'target': tensor([1.1000], dtype=torch.float64)}\n",
      "CModel loaded...\n",
      "IdentityModel(\n",
      "  (layers): ModuleList(\n",
      "    (0): Identity()\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'embed_3': Embedding(4, 8, padding_idx=0), 'embed_4': Embedding(5, 8, padding_idx=0)}\n",
      "out:  tensor([ 1.0040e+01,  2.0000e-02,  3.0000e-02,  4.0000e-02,  5.0000e-02,\n",
      "         2.0000e-02,  3.0000e-02,  4.0000e-02,  5.0000e-02,  2.4158e-01,\n",
      "        -9.9165e-01,  1.9839e-01, -1.2406e+00,  2.4568e-01,  9.3579e-02,\n",
      "         4.2608e-01,  3.7012e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.8903e+00,\n",
      "        -3.2046e-01,  1.0102e+00,  1.5032e+00,  8.5616e-01,  8.2170e-03,\n",
      "        -1.0493e+00,  2.3502e-01, -1.8903e+00, -3.2046e-01,  1.0102e+00,\n",
      "         1.5032e+00,  8.5616e-01,  8.2170e-03, -1.0493e+00,  2.3502e-01,\n",
      "         6.3236e-01, -3.0318e-01,  7.2113e-01, -2.0182e+00, -1.0470e+00,\n",
      "        -9.2545e-01,  1.3512e+00,  9.3729e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "       dtype=torch.float64)\n",
      "out.shape:  torch.Size([89])\n"
     ]
    }
   ],
   "source": [
    "#example cosmosis dataset (CDataset)\n",
    "import numpy as np\n",
    "\n",
    "class ExampleDataset(CDataset):\n",
    "    #zero is the lookup for the padding index \n",
    "    embed_lookup = {'feature_4': {'a': 1,'b': 2,'c': 3,'d': 4, '0': 0},\n",
    "                    'feature_3': {'z1': 1, 'y1': 2, 'x1': 3, '0': 0},\n",
    "                    'feature_6': {'e': 1, 'f': 2, 'g': 3, '0': 0}}\n",
    "    \n",
    "    def load_data(self, boom='bust'):\n",
    "        \n",
    "        datadic = {1: {'feature_1': np.asarray([.04]),\n",
    "                       'feature_2': np.asarray([[.02,.03],[.04,.05]]),\n",
    "                       'feature_3': np.asarray(['z1']),\n",
    "                       'feature_4': np.asarray(['c','c','d']),\n",
    "                       'feature_5': np.asarray([1.1]),\n",
    "                       'feature_6': np.asarray(['e','f','g'])},\n",
    "                   2: {'feature_1': np.asarray([.03]),\n",
    "                       'feature_2': np.asarray([[.1,.2],[.3,.4]]),\n",
    "                       'feature_3': np.asarray(['x1','z1','y1']),\n",
    "                       'feature_4': np.asarray(['d','a','d']),\n",
    "                       'feature_5': np.asarray([1.2]),\n",
    "                       'feature_6': np.asarray(['f','f','g'])}}\n",
    "        \n",
    "        print(boom)\n",
    "        return datadic\n",
    "    \n",
    "class ExampleTransform():\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        \n",
    "    def __call__(self, arr):\n",
    "        return np.add(arr, self.num)\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "lookup_feature_6 = ExampleDataset.embed_lookup['feature_6']\n",
    "ds_param = {'train_param': {'input_dict': {\n",
    "                                           'X2': ['feature_1','feature_2'], \n",
    "                                           'X3': ['feature_2'],\n",
    "                                           'embed_3': ['feature_3'],\n",
    "                                           'embed_4': ['feature_4'],\n",
    "                                           'target': ['feature_5'],\n",
    "                                            },\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(5), EmbedLookup(lookup_feature_4), AsTensor()],\n",
    "                                           'feature_5': [AsTensor()],\n",
    "                                           'feature_6': [Pad1d(5), EmbedLookup(lookup_feature_6), AsTensor()]},\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'X': ['X2', 'X3'],\n",
    "               'y': ['target'],\n",
    "               'embed_param': {\n",
    "                               'embed_3': (4,8,0,False),\n",
    "                               'embed_4': (5,8,0,False),\n",
    "                               'flatten': True}}\n",
    "im = IdentityModel(model_param)\n",
    "print(im)\n",
    "print('embedding_layer: ', im.embedding_layer)\n",
    "\n",
    "out = im(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X1': tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'X2': tensor([3, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'y': tensor([1.1000], dtype=torch.float64)}\n",
      "CModel loaded...\n",
      "GPT(\n",
      "  (layers): ModuleList(\n",
      "    (0): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=16, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=16, bias=True)\n",
      "          (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'X1': Embedding(4, 16, padding_idx=0), 'X2': Embedding(5, 16, padding_idx=0)}\n",
      "out:  tensor([[ 1.2094,  1.2635,  0.6876, -0.4969, -0.8208,  0.1942,  0.0511,  0.4599,\n",
      "         -0.4415, -0.0548,  0.6127, -1.7321, -0.6788,  2.1044, -1.0158, -1.3421],\n",
      "        [ 0.3863,  0.7280, -0.1481, -1.1598,  0.0733,  1.1568,  0.5671, -1.4690,\n",
      "         -2.3168,  0.1302,  1.1172, -0.6038,  0.9615, -0.9083,  1.1172,  0.3681],\n",
      "        [ 0.3379,  0.3176,  0.2541, -0.8901, -0.2958,  0.7344,  0.5816, -0.9990,\n",
      "         -2.5046,  0.2529,  1.3329, -1.1437,  0.6355, -0.6383,  1.5966,  0.4279],\n",
      "        [ 0.5714,  0.4272,  0.7177, -1.6822, -0.4915,  0.1621,  0.5273, -0.9531,\n",
      "         -2.1541,  0.2406,  1.6696, -0.7560,  0.7117, -0.6565,  1.2262,  0.4395],\n",
      "        [ 0.5607,  0.3745,  0.0735, -1.2682, -0.7714,  1.0141,  0.5310, -1.0366,\n",
      "         -0.5893, -1.1141,  1.5236, -1.7262,  1.2254, -0.6394,  1.3978,  0.4448],\n",
      "        [ 0.4212,  0.4422,  0.4187, -1.0991,  0.1996,  0.9043,  1.2167, -0.9173,\n",
      "         -2.2056, -0.6264,  1.4384, -0.6811,  0.5372, -1.2923,  1.1426,  0.1010],\n",
      "        [ 0.2672,  0.4326, -0.4746, -0.4448, -0.3779,  1.1885,  0.8033, -1.5455,\n",
      "         -2.2629,  0.2232,  1.0307, -1.4285,  1.0242, -0.0377,  1.0482,  0.5539],\n",
      "        [ 0.3771,  0.1716,  0.1726, -1.1248, -0.5705, -0.1635,  0.7965, -1.0647,\n",
      "         -2.4753,  0.3221,  1.6354, -0.1882,  1.0787, -0.5937,  1.3759,  0.2510],\n",
      "        [ 0.3944,  0.5565,  0.5968, -1.2074, -0.4972,  1.0539,  0.8512, -1.1469,\n",
      "         -2.3190,  0.0994,  1.2011, -1.1991,  0.5154, -0.4216,  1.2366,  0.2859],\n",
      "        [ 0.7340,  0.4357,  0.3281, -1.2601, -0.4864,  1.1919,  0.7785, -0.8879,\n",
      "         -2.3369,  0.1389,  1.0804, -0.7597,  0.7187, -0.9428,  1.3723, -0.1047],\n",
      "        [ 0.2128, -0.1719,  0.3210, -1.7526, -0.7045,  1.2027,  1.1437, -1.2378,\n",
      "         -0.5149, -0.0479,  1.8614, -1.5160,  0.4500, -0.7351,  0.9511,  0.5380],\n",
      "        [ 0.3102,  0.4027,  0.4129, -1.2761, -0.4535,  1.0431,  0.5499, -1.0089,\n",
      "         -2.4607, -0.3471,  1.2394, -0.5541,  0.9034, -0.6463,  1.3293,  0.5558]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "out.shape:  torch.Size([12, 16])\n"
     ]
    }
   ],
   "source": [
    "#example showing transformer inputs, outputs and parameters\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "lookup_feature_6 = ExampleDataset.embed_lookup['feature_6']\n",
    "ds_param = {'train_param': {'input_dict': {'X1': ['feature_3'],\n",
    "                                           'X2': ['feature_4'],\n",
    "                                           'y': ['feature_5']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(12), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(12), EmbedLookup(lookup_feature_4), AsTensor()],\n",
    "                                           'feature_5': [AsTensor()],\n",
    "                                           'feature_6': [EmbedLookup(lookup_feature_6), AsTensor()]},\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'd_model': 16, # matches embedding dimension\n",
    "               'nhead': 4, \n",
    "               'num_layers': 2,\n",
    "               'dim_feedforward': 128,\n",
    "               'embed_param': {'X1': (4,16,0,True), # matches embedding_input key\n",
    "                               'X2': (5,16,0,True)}} # matches d_model dimension\n",
    "                                 \n",
    "\n",
    "gpt = GPT(model_param)\n",
    "print(gpt)\n",
    "print('embedding_layer: ', gpt.embedding_layer)\n",
    "out = gpt(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape) # (feature_length, embedding_lenth) = (12, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example GPT\n",
    "lookup_feature = Dataset.embed_lookup[]\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'model_key1': ['dataset_key2']},\n",
    "                                             'criterion_input': {'criterion__key': ['dataset_key3']},\n",
    "                                             'embedding_input': {'embedding_key1': ['dataset_key1']}},\n",
    "                              'transforms': {'dataset_key1': [Pad1d(), EmbedLookup(lookup_feature), AsTensor()],\n",
    "                                             'dataset_key2': [AsTensor()],\n",
    "                                             'dataset_key3': [AsTensor()]}}}\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "                'd_model': 16, # matches embedding dimension\n",
    "                'nhead': 4, \n",
    "                'num_layers': 2,\n",
    "                'dim_feedforward': 128,\n",
    "                'embed_param': {'X': [('embed_3',4,16,0,True,False)], # matches embedding_input key\n",
    "                                 'X1': [('embed_4',5,16,0,True,False)]}} # matches d_model dimension\n",
    "                                       \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([DS], \n",
    "          GPT,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Optimizer, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=LossFunction,\n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=12, epochs=1, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating scikit learn make_regression dataset...\n",
      "CDataset created...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_input': array([-7.16654241e-01, -8.26320589e-01,  1.39745605e+00, -1.05533004e-01,\n",
       "         2.04885125e+00,  1.42904434e+02], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS)\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X'],\n",
    "                                                           'y': ['y']}},\n",
    "                              'dataset': 'make_regression',\n",
    "                              'sk_param': {'n_samples': 100,\n",
    "                                            'n_features': 5},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'float32'}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating scikit learn make_classification dataset...\n",
      "CDataset created...\n",
      "{'model_input': tensor([ 2.2253,  0.0539, -0.6047,  1.6087,  3.6594, -4.7625,  2.0766,  0.4928,\n",
      "        -1.6916, -0.4152, -0.2224,  1.6622,  2.4593,  1.2443, -0.3601,  0.7799,\n",
      "         0.5788,  0.4170, -6.9852, -0.8588,  0.6626,  2.4645, -0.4166,  2.9019,\n",
      "        -0.2515,  1.8335,  0.6526,  1.1392,  2.2138, -4.3454,  1.0000])}\n"
     ]
    }
   ],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS)\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X'],\n",
    "                                                           'y': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'transforms': {'y': [AsTensor()],\n",
    "                                             'X': [AsTensor()]},\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_param': {'n_samples': 1000,\n",
    "                                            'n_features': 30,\n",
    "                                            'n_informative': 20,\n",
    "                                            'n_clusters_per_class': 3,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.1,\n",
    "                                            'n_classes': 4}}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "print(sk[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating torch vision MNIST dataset...\n",
      "CDataset created...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_input': {'image': <PIL.Image.Image image mode=L size=224x224>},\n",
       " 'criterion_input': {'y': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS)\n",
    "ds_param={'dataset': 'MNIST',\n",
    "           'input_dict': {'model_input': {'features': ['images'],},\n",
    "                                          'y': ['labels']},\n",
    "           'tv_param': {'root': './data/',\n",
    "                         'train': True,\n",
    "                         'download': True,\n",
    "                         'transform': transforms.Compose([transforms.Resize(224)]),\n",
    "                         'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_param)\n",
    "tvds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating torch vision MNIST dataset...\n",
      "CDataset created...\n",
      "images to process: 60000\n",
      "images processed: 10000\n",
      "images processed: 20000\n",
      "images processed: 30000\n",
      "images processed: 40000\n",
      "images processed: 50000\n",
      "images processed: 60000\n",
      "mean: [33.33091590401786], stddev: [73.70246726596685]\n",
      "mean:  [33.33091590401786]\n",
      "stddev:  [73.70246726596685]\n"
     ]
    }
   ],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and PIL stats\n",
    "ds_param={'dataset': 'MNIST',\n",
    "          'tv_param': {'root': './data/',\n",
    "                       'train': True,\n",
    "                       'download': True,\n",
    "                       'transform': transforms.Compose([transforms.Resize(224)]),\n",
    "                       'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_param)\n",
    "ids = ImageDatasetStats(tvds)\n",
    "\n",
    "print('mean: ', ids.stats.mean)\n",
    "print('stddev: ', ids.stats.stddev)\n",
    "\n",
    "#mean: 33.3/255 = .13\n",
    "#stddev: 73.7/255 = .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating scikit learn make_regression dataset...\n",
      "CDataset created...\n",
      "FFNet model loaded...\n",
      "CModel loaded...\n",
      "running model on gpu...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'embedded_dict' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m\n\u001b[1;32m     25\u001b[0m sample_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_seed\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m88\u001b[39m,\n\u001b[1;32m     26\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplits\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m.7\u001b[39m,\u001b[38;5;241m.15\u001b[39m)}\n\u001b[1;32m     28\u001b[0m sched_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m.5\u001b[39m, \n\u001b[1;32m     29\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     30\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcooldown\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m---> 32\u001b[0m l \u001b[38;5;241m=\u001b[39m Learn([SKDS], \n\u001b[1;32m     33\u001b[0m           FFNet,\n\u001b[1;32m     34\u001b[0m           Metrics\u001b[38;5;241m=\u001b[39mMetrics,\n\u001b[1;32m     35\u001b[0m           Sampler\u001b[38;5;241m=\u001b[39mSelector, \n\u001b[1;32m     36\u001b[0m           Optimizer\u001b[38;5;241m=\u001b[39mAdam, \n\u001b[1;32m     37\u001b[0m           Scheduler\u001b[38;5;241m=\u001b[39mReduceLROnPlateau, \n\u001b[1;32m     38\u001b[0m           Criterion\u001b[38;5;241m=\u001b[39mMSELoss,\n\u001b[1;32m     39\u001b[0m           model_param\u001b[38;5;241m=\u001b[39mmodel_param, ds_param\u001b[38;5;241m=\u001b[39mds_param, sample_param\u001b[38;5;241m=\u001b[39msample_param,\n\u001b[1;32m     40\u001b[0m           opt_param\u001b[38;5;241m=\u001b[39mopt_param, sched_param\u001b[38;5;241m=\u001b[39msched_param, crit_param\u001b[38;5;241m=\u001b[39mcrit_param,\n\u001b[1;32m     41\u001b[0m           metrics_param\u001b[38;5;241m=\u001b[39mmetrics_param, \n\u001b[1;32m     42\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/cosmosis/learning.py:296\u001b[0m, in \u001b[0;36mLearn.__init__\u001b[0;34m(self, Datasets, Model, Sampler, Metrics, DataLoader, Optimizer, Scheduler, Criterion, ds_param, model_param, sample_param, opt_param, sched_param, crit_param, metrics_param, adapt, load_model, load_embed, save_model, batch_size, epochs, squeeze_y_pred, gpu, target)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m e\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mshuffle_train_val_idx()\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m no_grad():\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/cosmosis/learning.py:365\u001b[0m, in \u001b[0;36mLearn.run\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m    364\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 365\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(data)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msqueeze_y_pred: y_pred \u001b[38;5;241m=\u001b[39m squeeze(y_pred)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cosmo/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/cosmosis/model.py:160\u001b[0m, in \u001b[0;36mCModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    157\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data) \u001b[38;5;66;03m# mechanism for multiple model inputs\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(embedded_dict\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my): \u001b[38;5;66;03m# filter out already embedded features and target\u001b[39;00m\n\u001b[1;32m    161\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(data[k])\n\u001b[1;32m    163\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(embedded)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'embedded_dict' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 512, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'float32',\n",
    "                            'dataset': 'make_regression',\n",
    "                            'sk_param': {'n_samples':20000,\n",
    "                                         'n_features': 256,\n",
    "                                         'n_informative': 200}}}\n",
    "             \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=MSELoss,\n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=256, epochs=40, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 4,\n",
    "                'softmax': 'softmax',\n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'y': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'transforms': {'y': [SqueezeN()],\n",
    "                                             'X': []},\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_param': {'n_samples': 100000,\n",
    "                                            'n_features': 300,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_redundant': 5,\n",
    "                                            'n_repeated': 5,\n",
    "                                            'n_clusters_per_class': 5,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.05,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_param = {'report_interval': 30,\n",
    "                  'log_plot': False,\n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_param': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss,\n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          adapt=(300,256,.2), \n",
    "          squeeze_y_pred=False, batch_size=128, epochs=20, \n",
    "          save_model='demo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example inference with cosmosis sklearn classification dataset wrapper (SKDS) and custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 4, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'y': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_param': {'n_samples': 10000,\n",
    "                                            'n_features': 300,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_clusters_per_class': 3,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.1,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "\n",
    "metrics_param = {}\n",
    "opt_param = {}\n",
    "sample_param = {}\n",
    "sched_param = {}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=None,\n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          batch_size=128, epochs=1, load_model='demo_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnet18',\n",
    "                'in_channels': 3,\n",
    "                'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'download': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                           transforms.RandomRotation(10),\n",
    "                                                           transforms.Resize(64),\n",
    "                                                           transforms.ToTensor()]),\n",
    "                                          'target_transform': None,\n",
    "                                          'download': True}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                           'tv_param': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'download': True,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                         transforms.Resize(64),\n",
    "                                                         transforms.ToTensor()]),\n",
    "                                         'target_transform': None,\n",
    "                                         'download': True}}}\n",
    "\n",
    "metrics_param = {'report_interval': 30, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_param': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 1,\n",
    "                'cooldown': 1}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=CrossEntropyLoss, \n",
    "          model_param=model_param, ds_param=ds_param, sample_param=sample_param, \n",
    "          opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param, \n",
    "          batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnext50_32x4d',\n",
    "                'in_channels': 3,\n",
    "                'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                       transforms.RandomRotation(10),\n",
    "                                                       transforms.Resize(256),\n",
    "                                                       transforms.ToTensor()]),\n",
    "                                          'target_transform': None}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                           'tv_param': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                      transforms.Resize(256),\n",
    "                                                      transforms.ToTensor()]),\n",
    "                                         'target_transform': None}}}\n",
    "\n",
    "metrics_param = {'report_interval': 60, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_param': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss, \n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
