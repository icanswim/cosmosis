{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples using the icanswim/cosmosis data science and machine learning repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNet, tv_model\n",
    "from learning import Learn, Selector, Metrics\n",
    "from dataset import CDataset, SKDS, TVDS\n",
    "from dataset import ImageDatasetStats, AsTensor, Squeeze, DType\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of generic/custom dataset and transforms\n",
    "import numpy as np\n",
    "\n",
    "class DummyDataset(CDataset):\n",
    "\n",
    "    def load_data(self, boom='bust'):\n",
    "        \n",
    "        datadic = {1: {'feature_1': np.asarray([.04]),\n",
    "                       'feature_2': np.asarray([.02]),\n",
    "                       'feature_3': np.asarray(['z1']),\n",
    "                       'feature_4': np.asarray(['c','c','d']),\n",
    "                       'feature_5': np.asarray([1.1])},\n",
    "                   2: {'feature_1': np.asarray([.03]),\n",
    "                       'feature_2': np.asarray([.01]),\n",
    "                       'feature_3': np.asarray(['x1','z1','y1']),\n",
    "                       'feature_4': np.asarray(['d','a','d']),\n",
    "                       'feature_5': np.asarray([1.2])}}\n",
    "        \n",
    "        self.embed_lookup = {'feature_4': {'a': 1,'b': 2,'c': 3,'d': 4, '0': 0},\n",
    "                             'feature_3': {'z1': 1, 'y1': 2, 'x1': 3, '0': 0}}\n",
    "        \n",
    "        print(boom)\n",
    "        return datadic\n",
    "    \n",
    "class DummyTransform():\n",
    "    def __call__(self, arr):\n",
    "        return np.add(arr, 2)\n",
    "    \n",
    "class DummyTransformTwo():\n",
    "    def __call__(self, arr):\n",
    "        return np.multiply(arr, .1)\n",
    "    \n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X1': ['feature_1','feature_5'],\n",
    "                                                              'X2': ['feature_5'],\n",
    "                                                              'embed': ['feature_3']},\n",
    "                                             'criterion_input': {'y': ['feature_2'],\n",
    "                                                                  'embed': ['feature_4']}},\n",
    "                              'transform': [DummyTransform(), DummyTransformTwo()],\n",
    "                              'target_transform': [],\n",
    "                              'pad': 5,\n",
    "                              'pad_feats': ['feature_5','feature_4'],\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "d = DummyDataset(**ds_params['train_params'])\n",
    "d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of sklearn regression dataset wrapper\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'features': ['X']},\n",
    "                                             'criterion_input': {'targets': ['y']}},\n",
    "                              'dataset': 'make_regression',\n",
    "                              'sk_params': {'n_samples': 100,\n",
    "                                            'n_features': 5},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'float32'}}\n",
    "\n",
    "sk = SKDS(**ds_params['train_params'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of sklearn classification dataset wrapper\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'features': ['X']},\n",
    "                                             'criterion_input': {'targets': ['y']}},\n",
    "                              'dataset': 'make_classification',\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'sk_params': {'n_samples': 100,\n",
    "                                            'n_features': 10,\n",
    "                                            'n_informative': 8,\n",
    "                                            'n_clusters_per_class': 2,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.01,\n",
    "                                            'n_classes': 4}}}\n",
    "\n",
    "sk = SKDS(**ds_params['train_params'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of torchvision wrapper\n",
    "ds_params={'dataset': 'MNIST',\n",
    "           'input_dict': {'model_input': {'features': ['images'],},\n",
    "                          'criterion_input': {'targets': ['labels']}},\n",
    "           'tv_params': {'root': './data/',\n",
    "                         'train': True,\n",
    "                         'download': True,\n",
    "                         'transform': transforms.Compose([\n",
    "                                           transforms.Resize(224)]),\n",
    "                         'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_params)\n",
    "tvds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example of torchvision dataset wrapper with PIL transform\n",
    "ds_params={'dataset': 'MNIST',\n",
    "           'tv_params': {'root': './data/',\n",
    "                         'train': True,\n",
    "                         'download': True,\n",
    "                         'transform': transforms.Compose([\n",
    "                                           transforms.Resize(224)]),\n",
    "                         'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_params)\n",
    "ids = ImageDatasetStats(tvds)\n",
    "\n",
    "print('mean: ', ids.stats.mean)\n",
    "print('stddev: ', ids.stats.stddev)\n",
    "\n",
    "#mean: 33.3/255 = .13\n",
    "#stddev: 73.7/255 = .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating scikit learn make_regression dataset...\n",
      "CDataset created...\n",
      "FFNet model loaded...\n",
      "CModel loaded...\n",
      "running model on gpu...\n",
      "learning time: 0:00:02.589537\n",
      "epoch: 0, lr: 0.01\n",
      "train loss: 544149.2013888889, val loss: 436439.10511363635\n",
      "test loss: 13338.430841619318\n",
      "learning time: 0:00:09.122587\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Example sklearn regression dataset wrapper with custom model\n",
    "model_params = {'D_in': 256, \n",
    "                'H': 512, \n",
    "                'D_out': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'input_dict': {'model_input': {'X': ['X']},\n",
    "                                             'criterion_input': {'target': ['y']}},\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'float32',\n",
    "                              'dataset': 'make_regression',\n",
    "                              'as_tensor': True,\n",
    "                              'transform': [],\n",
    "                              'sk_params': {'n_samples':20000,\n",
    "                                            'n_features': 256,\n",
    "                                            'n_informative': 200}}}\n",
    "             \n",
    "metrics_params = {'report_interval': 10,\n",
    "                  'log_plot': True}                         \n",
    "             \n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet,\n",
    "          Metrics=Metrics,\n",
    "          Sampler=Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=MSELoss,\n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params,\n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params, \n",
    "          batch_size=256, epochs=10, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example sklearn classification dataset and metrics wrapper with custom model\n",
    "model_params = {'D_in': 256, \n",
    "                'H': 128, \n",
    "                'D_out': 4, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'features': 'X',\n",
    "                              'targets': 'y',\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_params': {'n_samples': 100000,\n",
    "                                            'n_features': 300,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_clusters_per_class': 3,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.1,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 5,\n",
    "                'cooldown': 5}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss,\n",
    "          model_params=model_params, ds_params=ds_params, \n",
    "          sample_params=sample_params, opt_params=opt_params, \n",
    "          sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          adapt=(300,256,.2), batch_size=128, epochs=10, squeeze_y=True, save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example inference with a sklearn classification dataset and metrics wrapper with custom model\n",
    "model_params = {'D_in': 256, \n",
    "                'H': 128, \n",
    "                'D_out': 4, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_params = {'train_params': {'features': 'X',\n",
    "                              'targets': 'y',\n",
    "                              'features_dtype': 'float32',\n",
    "                              'targets_dtype': 'int64',\n",
    "                              'dataset': 'make_classification',\n",
    "                              'sk_params': {'n_samples': 10000,\n",
    "                                            'n_features': 300,\n",
    "                                            'n_informative': 200,\n",
    "                                            'n_clusters_per_class': 3,\n",
    "                                            'flip_y': 0.05,\n",
    "                                            'class_sep': 0.1,\n",
    "                                            'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score',\n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 5,\n",
    "                'cooldown': 5}\n",
    "\n",
    "l = Learn([SKDS], \n",
    "          FFNet, \n",
    "          Sampler=Selector,\n",
    "          Metrics=Metrics,\n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=None,\n",
    "          model_params=model_params, ds_params=ds_params, \n",
    "          sample_params=sample_params, opt_params=opt_params, \n",
    "          sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=128, epochs=1, squeeze_y=True, load_model='20220813_2127.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example torchvision dataset, transforms and model wrapper\n",
    "model_params = {'model_name': 'resnet18',\n",
    "                'in_channels': 3,\n",
    "                'tv_params': {'num_classes': 10}}\n",
    "\n",
    "ds_params={'train_params': {'dataset': 'CIFAR10',\n",
    "                            'tv_params': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'download': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                           transforms.RandomRotation(10),\n",
    "                                                           transforms.Resize(64),\n",
    "                                                           transforms.ToTensor()]),\n",
    "                                          'target_transform': None,\n",
    "                                          'download': True}},\n",
    "           'test_params': {'dataset': 'CIFAR10',\n",
    "                           'tv_params': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'download': True,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                         transforms.Resize(64),\n",
    "                                                         transforms.ToTensor()]),\n",
    "                                         'target_transform': None,\n",
    "                                         'download': True}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 1,\n",
    "                'cooldown': 1}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=CrossEntropyLoss, \n",
    "          model_params=model_params, ds_params=ds_params, sample_params=sample_params, \n",
    "          opt_params=opt_params, sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params, \n",
    "          batch_size=16, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example torchvision dataset and model wrapper\n",
    "model_params = {'model_name': 'resnext50_32x4d',\n",
    "                'in_channels': 3,\n",
    "                'tv_params': {'num_classes': 10}}\n",
    "\n",
    "ds_params={'train_params': {'dataset': 'CIFAR10',\n",
    "                            'tv_params': {'root': './data/',\n",
    "                                          'train': True,\n",
    "                                          'transform': transforms.Compose([\n",
    "                                                       transforms.RandomRotation(10),\n",
    "                                                       transforms.Resize(256),\n",
    "                                                       transforms.ToTensor()]),\n",
    "                                          'target_transform': None}},\n",
    "           'test_params': {'dataset': 'CIFAR10',\n",
    "                           'tv_params': {'root': './data/',\n",
    "                                         'train': False,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                      transforms.Resize(256),\n",
    "                                                      transforms.ToTensor()]),\n",
    "                                         'target_transform': None}}}\n",
    "\n",
    "metrics_params = {'report_interval': 10, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_params': {'average': 'macro',\n",
    "                                'multi_class': 'ovr'}}\n",
    "\n",
    "opt_params = {'lr': 0.01}\n",
    "\n",
    "crit_params = {'reduction': 'sum'}\n",
    "\n",
    "sample_params = {'set_seed': 88,\n",
    "                 'splits': (.8,),\n",
    "                 'subset': .1}\n",
    "\n",
    "sched_params = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 2}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss, \n",
    "          model_params=model_params, ds_params=ds_params, \n",
    "          sample_params=sample_params, opt_params=opt_params, \n",
    "          sched_params=sched_params, crit_params=crit_params,\n",
    "          metrics_params=metrics_params,\n",
    "          batch_size=16, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
