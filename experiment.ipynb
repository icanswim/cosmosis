{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a series of examples demonstrating the use of the icanswim/cosmosis repo \n",
    "## for data science and machine learning projects.\n",
    "## This repo is intended to be used as the boiler plate for data science and machine learning projects.\n",
    "## See the icanswim/qchem repo for a demonstration of the use of this (icanswim/cosmosis) repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import FFNet, tv_model, IdentityModel, GPT\n",
    "from learning import Learn, Selector, Metrics\n",
    "from dataset import CDataset, SKDS, TVDS, ExampleDataset\n",
    "from dataset import ImageDatasetStats, AsTensor, SqueezeN, DType, Pad1d, EmbedLookup, Reshape\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cosmosis blank parameters\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['feature_1','feature_2'],\n",
    "                                           'feature_3': ['feature_3']},\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()]},\n",
    "                            'boom': 'bang'}}\n",
    "\n",
    "model_param = {'some_param': 128,\n",
    "               'X': None,\n",
    "               'y': 'y',\n",
    "               'embed_param': {'feature_3': (voc,vec,padding_idx,trainable),\n",
    "                               'some_param': True,\n",
    "                               'flatten': True}} \n",
    "                                       \n",
    "metrics_param = {'report_interval': 10,\n",
    "                 'log_plot': True,\n",
    "                 'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "learn = Learn([DS], \n",
    "              Model,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Optimizer, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=LossFunction,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=12, epochs=1, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X2': tensor([10.0400,  0.0200,  0.0300,  0.0400,  0.0500], dtype=torch.float64), 'X3': tensor([0.0200, 0.0300, 0.0400, 0.0500], dtype=torch.float64), 'embed_3': tensor([1, 0, 0, 0, 0]), 'embed_4': tensor([3, 3, 4, 0, 0]), 'target': tensor([1.1000], dtype=torch.float64)}\n",
      "CModel loaded...\n",
      "IdentityModel(\n",
      "  (layers): ModuleList(\n",
      "    (0): Identity()\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'embed_3': Embedding(4, 8, padding_idx=0), 'embed_4': Embedding(5, 8, padding_idx=0)}\n",
      "out:  tensor([10.0400,  0.0200,  0.0300,  0.0400,  0.0500,  0.0200,  0.0300,  0.0400,\n",
      "         0.0500,  1.1181, -0.5635, -0.4410,  2.1613, -1.6953,  0.2718, -1.7532,\n",
      "        -0.1093,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -1.5853, -0.7816,  1.0675,  0.3719, -0.3022,  0.7275,  0.8327,\n",
      "         0.1858, -1.5853, -0.7816,  1.0675,  0.3719, -0.3022,  0.7275,  0.8327,\n",
      "         0.1858,  0.1805, -0.3676,  0.2967,  0.2133, -0.2867,  0.7710,  1.1603,\n",
      "         0.1036,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000], dtype=torch.float64)\n",
      "out.shape:  torch.Size([89])\n"
     ]
    }
   ],
   "source": [
    "#example cosmosis dataset (CDataset)\n",
    "\n",
    "class ExampleTransform():\n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        \n",
    "    def __call__(self, arr):\n",
    "        return np.add(arr, self.num)\n",
    "\n",
    "\n",
    "class ExampleDataset(CDataset):\n",
    "    #zero is the lookup for the padding index \n",
    "    embed_lookup = {'feature_4': {'a': 1,'b': 2,'c': 3,'d': 4, '0': 0},\n",
    "                    'feature_3': {'z1': 1, 'y1': 2, 'x1': 3, '0': 0},\n",
    "                    'feature_6': {'e': 1, 'f': 2, 'g': 3, '0': 0}}\n",
    "    \n",
    "    def load_data(self, boom='bust'):\n",
    "        \n",
    "        datadic = {1: {'feature_1': np.asarray([.04]),\n",
    "                       'feature_2': np.asarray([[.02,.03],[.04,.05]]),\n",
    "                       'feature_3': np.asarray(['z1']),\n",
    "                       'feature_4': np.asarray(['c','c','d']),\n",
    "                       'feature_5': np.asarray([1.1]),\n",
    "                       'feature_6': np.asarray(['e','f','g'])},\n",
    "                   2: {'feature_1': np.asarray([.03]),\n",
    "                       'feature_2': np.asarray([[.1,.2],[.3,.4]]),\n",
    "                       'feature_3': np.asarray(['x1','z1','y1']),\n",
    "                       'feature_4': np.asarray(['d','a','d']),\n",
    "                       'feature_5': np.asarray([1.2]),\n",
    "                       'feature_6': np.asarray(['f','f','g'])}}\n",
    "        \n",
    "        print(boom)\n",
    "        return datadic\n",
    "    \n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "lookup_feature_6 = ExampleDataset.embed_lookup['feature_6']\n",
    "ds_param = {'train_param': {'input_dict': {\n",
    "                                           'X2': ['feature_1','feature_2'], \n",
    "                                           'X3': ['feature_2'],\n",
    "                                           'embed_3': ['feature_3'],\n",
    "                                           'embed_4': ['feature_4'],\n",
    "                                           'target': ['feature_5'],\n",
    "                                            },\n",
    "                            'transforms': {'feature_1': [ExampleTransform(10), Reshape(-1), AsTensor()],\n",
    "                                           'feature_2': [Reshape(-1), AsTensor()],\n",
    "                                           'feature_3': [Pad1d(5), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(5), EmbedLookup(lookup_feature_4), AsTensor()],\n",
    "                                           'feature_5': [AsTensor()],\n",
    "                                           'feature_6': [Pad1d(5), EmbedLookup(lookup_feature_6), AsTensor()]},\n",
    "                            'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'X': ['X2', 'X3'],\n",
    "               'y': 'target',\n",
    "               'embed_param': {'embed_3': (4,8,0,False),\n",
    "                               'embed_4': (5,8,0,False),\n",
    "                               'flatten': True}}\n",
    "\n",
    "im = IdentityModel(model_param)\n",
    "print(im)\n",
    "print('embedding_layer: ', im.embedding_layer)\n",
    "\n",
    "out = im(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape) # (1+4+4+5*8+5*8) = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bang\n",
      "CDataset created...\n",
      "ed[1]:  {'X1': tensor([1, 0, 0, 0, 0, 0]), 'X2': tensor([3, 3, 4, 0, 0, 0])}\n",
      "CModel loaded...\n",
      "GPT(\n",
      "  (linear_head): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=8, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=8, bias=True)\n",
      "          (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "embedding_layer:  {'X1': Embedding(4, 8, padding_idx=0), 'X2': Embedding(5, 8, padding_idx=0)}\n",
      "out:  tensor([[-1.6512,  1.0288,  0.3783, -0.1369],\n",
      "        [-0.2773, -1.0490, -0.1420, -1.2721],\n",
      "        [-0.3204,  1.5912,  1.5173,  1.3198],\n",
      "        [-0.1626, -1.0216,  0.1459, -0.6956],\n",
      "        [ 0.9245, -0.5134, -1.8737, -0.5636],\n",
      "        [ 1.4870, -0.0360, -0.0258,  1.3483]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "out.shape:  torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "#example showing transformer inputs, outputs and parameters\n",
    "\n",
    "lookup_feature_3 = ExampleDataset.embed_lookup['feature_3']\n",
    "lookup_feature_4 = ExampleDataset.embed_lookup['feature_4']\n",
    "ds_param = {'train_param': {'input_dict': {'X1': ['feature_3'],\n",
    "                                           'X2': ['feature_4']},\n",
    "                            'transforms': {'feature_3': [Pad1d(6), EmbedLookup(lookup_feature_3), AsTensor()],\n",
    "                                           'feature_4': [Pad1d(6), EmbedLookup(lookup_feature_4), AsTensor()]},\n",
    "                              'boom': 'bang'}}\n",
    "    \n",
    "ed = ExampleDataset(**ds_param['train_param'])\n",
    "print('ed[1]: ', ed[1])\n",
    "\n",
    "model_param = {'device': 'cpu',\n",
    "               'd_model': 8, # matches embedding dimension\n",
    "               'n_head': 2, \n",
    "               'num_layers': 2,\n",
    "               'd_vocab': 4, # determines the linear_head dim\n",
    "               'linear_head': True,\n",
    "               'embed_param': {'X1': (4,8,0,True), # embed key matches input_dict key ('X1')\n",
    "                               'X2': (5,8,0,True), # vector dimension matches d_model dimension\n",
    "                } \n",
    "              }                                  \n",
    "                 \n",
    "                                 \n",
    "gpt = GPT(model_param)\n",
    "print(gpt)\n",
    "print('embedding_layer: ', gpt.embedding_layer)\n",
    "out = gpt(ed[1])\n",
    "print('out: ', out)\n",
    "print('out.shape: ', out.shape) \n",
    "# (feature_length, embedding_lenth) x (linear_head, d_vocab) = (6, 8) x (8, 4) = (6 x 4)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating scikit learn make_regression dataset...\n",
      "CDataset created...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_input': array([ 1.9947108 ,  0.58146507, -1.3930557 ,  0.8433151 , -1.6775603 ],\n",
       "       dtype=float32),\n",
       " 'y': array([23.710886], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS)\n",
    "                            \n",
    "ds_param = {'train_param': {'input_dict': {'model_input': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'dataset': 'make_regression',\n",
    "                            'sk_param': {'n_samples': 100,\n",
    "                                         'n_features': 5},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'float32'}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "sk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS)\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'int64',\n",
    "                            'transforms': {'y': [AsTensor()],\n",
    "                                           'X': [AsTensor()]},\n",
    "                            'dataset': 'make_classification',\n",
    "                            'sk_param': {'n_samples': 1000,\n",
    "                                         'n_features': 30,\n",
    "                                         'n_informative': 20,\n",
    "                                         'n_clusters_per_class': 3,\n",
    "                                         'flip_y': 0.05,\n",
    "                                         'class_sep': 0.1,\n",
    "                                         'n_classes': 4}}}\n",
    "\n",
    "sk = SKDS(**ds_param['train_param'])\n",
    "\n",
    "print(sk[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS)\n",
    "ds_param = {'train_param': {'input_dict': {'features': ['images'],\n",
    "                                           'y': ['labels']},\n",
    "                            'dataset': 'MNIST',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                         'train': True,\n",
    "                                         'download': True,\n",
    "                                         'transform': transforms.Compose([transforms.Resize(224)]),\n",
    "                                         'target_transform': None}}}\n",
    "\n",
    "tvds = TVDS(**ds_param['train_param'])\n",
    "tvds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and PIL stats\n",
    "ds_param={'dataset': 'MNIST',\n",
    "          'tv_param': {'root': './data/',\n",
    "                       'train': True,\n",
    "                       'download': True,\n",
    "                       'transform': transforms.Compose([transforms.Resize(224)]),\n",
    "                       'target_transform': None}}\n",
    "\n",
    "tvds = TVDS(**ds_param)\n",
    "ids = ImageDatasetStats(tvds)\n",
    "\n",
    "print('mean: ', ids.stats.mean)\n",
    "print('stddev: ', ids.stats.stddev)\n",
    "\n",
    "#mean: 33.3/255 = .13\n",
    "#stddev: 73.7/255 = .29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn regression dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 512, \n",
    "                'out_channels': 1, \n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'float32',\n",
    "                            'dataset': 'make_regression',\n",
    "                            'sk_param': {'n_samples':20000,\n",
    "                                         'n_features': 256,\n",
    "                                         'n_informative': 200}}}\n",
    "             \n",
    "metrics_param = {'report_interval': 10,\n",
    "                  'log_plot': True,\n",
    "                  'min_lr': .005} #break if learning rate falls below                        \n",
    "             \n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5, \n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "learn = Learn([SKDS], \n",
    "              FFNet,\n",
    "              Metrics=Metrics,\n",
    "              Sampler=Selector, \n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=MSELoss,\n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param,\n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=256, epochs=40, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis sklearn classification dataset wrapper (SKDS) with sklearn metrics (Metrics) and \n",
    "#custom model (FFNet)\n",
    "model_param = {'in_channels': 256, \n",
    "                'hidden': 128, \n",
    "                'out_channels': 4,\n",
    "                'softmax': 'softmax',\n",
    "                'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'int64',\n",
    "                            'transforms': {'y': [SqueezeN()],\n",
    "                                           'X': []},\n",
    "                            'dataset': 'make_classification',\n",
    "                            'sk_param': {'n_samples': 100000,\n",
    "                                         'n_features': 300,\n",
    "                                         'n_informative': 200,\n",
    "                                         'n_redundant': 5,\n",
    "                                         'n_repeated': 5,\n",
    "                                         'n_clusters_per_class': 5,\n",
    "                                         'flip_y': 0.05,\n",
    "                                         'class_sep': 0.05,\n",
    "                                         'n_classes': 4}}}\n",
    "                                     \n",
    "metrics_param = {'report_interval': 30,\n",
    "                 'log_plot': True,\n",
    "                 'sk_metric_name': 'roc_auc_score',\n",
    "                 'sk_param': {'average': 'macro',\n",
    "                              'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                 'splits': (.7,.15)}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "                'patience': 2,\n",
    "                'cooldown': 1}\n",
    "\n",
    "learm = Learn([SKDS], \n",
    "              FFNet, \n",
    "              Sampler=Selector,\n",
    "              Metrics=Metrics,\n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=CrossEntropyLoss,\n",
    "              model_param=model_param, ds_param=ds_param, \n",
    "              sample_param=sample_param, opt_param=opt_param, \n",
    "              sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param,\n",
    "              adapt=(300,256,.2), \n",
    "              squeeze_y_pred=False, batch_size=128, epochs=20, \n",
    "              save_model='demo_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example inference with cosmosis sklearn classification dataset wrapper (SKDS) and custom model (FFNet)\n",
    "\n",
    "model_param = {'in_channels': 256, \n",
    "               'hidden': 128, \n",
    "               'out_channels': 4, \n",
    "               'model_name': 'funnel'}\n",
    "\n",
    "ds_param = {'train_param': {'input_dict': {'X': ['X'],\n",
    "                                           'y': ['y']},\n",
    "                            'features_dtype': 'float32',\n",
    "                            'targets_dtype': 'int64',\n",
    "                            'dataset': 'make_classification',\n",
    "                            'sk_param': {'n_samples': 10000,\n",
    "                                         'n_features': 300,\n",
    "                                         'n_informative': 200,\n",
    "                                         'n_clusters_per_class': 3,\n",
    "                                         'flip_y': 0.05,\n",
    "                                         'class_sep': 0.1,\n",
    "                                         'n_classes': 4}}}\n",
    "                                     \n",
    "learn = Learn([SKDS], \n",
    "              FFNet, \n",
    "              Sampler=Selector,\n",
    "              Metrics=Metrics,\n",
    "              Optimizer=Adam, \n",
    "              Scheduler=ReduceLROnPlateau, \n",
    "              Criterion=None,\n",
    "              model_param=model_param, ds_param=ds_param, \n",
    "              batch_size=128, epochs=1, load_model='demo_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision image dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnet18',\n",
    "               'in_channels': 3,\n",
    "               'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                          'tv_param': {'root': './data/',\n",
    "                                       'train': True,\n",
    "                                       'download': True,\n",
    "                                       'transform': transforms.Compose([\n",
    "                                                           transforms.RandomRotation(10),\n",
    "                                                           transforms.Resize(64),\n",
    "                                                           transforms.ToTensor()]),\n",
    "                                       'target_transform': None,\n",
    "                                       'download': True}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                          'tv_param': {'root': './data/',\n",
    "                                       'train': False,\n",
    "                                       'download': True,\n",
    "                                       'transform': transforms.Compose([\n",
    "                                                         transforms.Resize(64),\n",
    "                                                         transforms.ToTensor()]),\n",
    "                                       'target_transform': None,\n",
    "                                       'download': True}}}\n",
    "\n",
    "metrics_param = {'report_interval': 30, \n",
    "                 'sk_metric_name': 'roc_auc_score', \n",
    "                 'sk_param': {'average': 'macro',\n",
    "                              'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.8,),\n",
    "                'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "               'patience': 1,\n",
    "               'cooldown': 1}\n",
    "\n",
    "learn = Learn([TVDS,TVDS], \n",
    "              tv_model, \n",
    "              Selector, \n",
    "              Optimizer=Adam, Scheduler=ReduceLROnPlateau, Criterion=CrossEntropyLoss, \n",
    "              model_param=model_param, ds_param=ds_param, sample_param=sample_param, \n",
    "              opt_param=opt_param, sched_param=sched_param, crit_param=crit_param,\n",
    "              metrics_param=metrics_param, \n",
    "              batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example cosmosis torchvision dataset wrapper (TVDS) with transforms and \n",
    "#torchvision model wrapper (tv_model)\n",
    "model_param = {'model_name': 'resnext50_32x4d',\n",
    "                'in_channels': 3,\n",
    "                'tv_param': {'num_classes': 10}}\n",
    "\n",
    "ds_param={'train_param': {'dataset': 'CIFAR10',\n",
    "                            'tv_param': {'root': './data/',\n",
    "                                         'train': True,\n",
    "                                         'transform': transforms.Compose([\n",
    "                                                       transforms.RandomRotation(10),\n",
    "                                                       transforms.Resize(256),\n",
    "                                                       transforms.ToTensor()]),\n",
    "                                         'target_transform': None}},\n",
    "           'test_param': {'dataset': 'CIFAR10',\n",
    "                           'tv_param': {'root': './data/',\n",
    "                                        'train': False,\n",
    "                                        'transform': transforms.Compose([\n",
    "                                                      transforms.Resize(256),\n",
    "                                                      transforms.ToTensor()]),\n",
    "                                        'target_transform': None}}}\n",
    "\n",
    "metrics_param = {'report_interval': 60, \n",
    "                  'sk_metric_name': 'roc_auc_score', \n",
    "                  'sk_param': {'average': 'macro',\n",
    "                               'multi_class': 'ovr'}}\n",
    "\n",
    "opt_param = {'lr': 0.01}\n",
    "\n",
    "crit_param = {'reduction': 'sum'}\n",
    "\n",
    "sample_param = {'set_seed': 88,\n",
    "                'splits': (.8,),\n",
    "                'subset': .1}\n",
    "\n",
    "sched_param = {'factor': .5,\n",
    "               'patience': 2,\n",
    "               'cooldown': 2}\n",
    "\n",
    "l = Learn([TVDS,TVDS], \n",
    "          tv_model, \n",
    "          Selector, \n",
    "          Optimizer=Adam, \n",
    "          Scheduler=ReduceLROnPlateau, \n",
    "          Criterion=CrossEntropyLoss, \n",
    "          model_param=model_param, ds_param=ds_param, \n",
    "          sample_param=sample_param, opt_param=opt_param, \n",
    "          sched_param=sched_param, crit_param=crit_param,\n",
    "          metrics_param=metrics_param,\n",
    "          batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
